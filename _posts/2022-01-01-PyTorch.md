---
layout: post
comments: true
title: "PyTorch"
date: 2022-02-09 01:09:00
tags: language
---

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---


## 总览

首先列出PyTorch的参考资料：

1. PyTorch官网：https://pytorch.org/
这里包含了tutorial、API文档等等。
2. 一个不错的介绍PyTorch的博客：https://github.com/jcjohnson/pytorch-examples
3. PyTorch源码的Github页：https://github.com/pytorch/pytorch
在PyTorch官网上也可以找到网页版的源码介绍，是一模一样的。
4. 这里开了个介绍PyTorch源码的博客：https://zhuanlan.zhihu.com/p/328674159
5. 这是PyTorch的一个作者写的介绍内部机理的博客：http://blog.ezyang.com/2019/05/pytorch-internals/


本post不会重复参考资料里的内容，但可能会对其进行补充。本post主要会对重要的PyTorch内容进行补充介绍，其中可能会综合汇总其他人博客里的内容（会标明出处），以达到对PyTorch常用内容可以迅速复习的目的。

本post内容会与post：CUDA学习的内容联动。

## 杂项

### 1. PyTorch优雅模板

**版本一：**

```python
### 一、导入包以及设置随机种子
import numpy as np
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

import random
seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)

### 二、以类的方式定义超参数
class argparse():
    pass

args = argparse()
args.epochs, args.learning_rate, args.patience = [30, 0.001, 4]
args.hidden_size, args.input_size= [40, 30]
args.device, = [torch.device("cuda:0" if torch.cuda.is_available() else "cpu"),]

### 三、定义自己的模型
class Your_model(nn.Module):
    def __init__(self):
        super(Your_model, self).__init__()
        pass
        
    def forward(self,x):
        pass
        return x

### 四、定义早停类(此步骤可以省略)
class EarlyStopping():
    def __init__(self,patience=7,verbose=False,delta=0):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta
    def __call__(self,val_loss,model,path):
        print("val_loss={}".format(val_loss))
        score = -val_loss
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss,model,path)
        elif score < self.best_score+self.delta:
            self.counter+=1
            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter>=self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss,model,path)
            self.counter = 0
    def save_checkpoint(self,val_loss,model,path):
        if self.verbose:
            print(
                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), path+'/'+'model_checkpoint.pth')
        self.val_loss_min = val_loss

### 五、定义自己的数据集Dataset,DataLoader
class Dataset_name(Dataset):
    def __init__(self, flag='train'):
        assert flag in ['train', 'test', 'valid']
        self.flag = flag
        self.__load_data__()

    def __getitem__(self, index):
        pass
    def __len__(self):
        pass

    def __load_data__(self, csv_paths: list):
        pass
        print(
            "train_X.shape:{}\ntrain_Y.shape:{}\nvalid_X.shape:{}\nvalid_Y.shape:{}\n"
            .format(self.train_X.shape, self.train_Y.shape, self.valid_X.shape, self.valid_Y.shape))

train_dataset = Dataset_name(flag='train')
train_dataloader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)
valid_dataset = Dataset_name(flag='valid')
valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=True)

### 六、实例化模型，设置loss，优化器等
model = Your_model().to(args.device)
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(Your_model.parameters(),lr=args.learning_rate)

train_loss = []
valid_loss = []
train_epochs_loss = []
valid_epochs_loss = []

early_stopping = EarlyStopping(patience=args.patience,verbose=True)

### 七、开始训练以及调整lr
for epoch in range(args.epochs):
    Your_model.train()
    train_epoch_loss = []
    for idx,(data_x,data_y) in enumerate(train_dataloader,0):
        data_x = data_x.to(torch.float32).to(args.device)
        data_y = data_y.to(torch.float32).to(args.device)
        outputs = Your_model(data_x)
        optimizer.zero_grad()
        loss = criterion(data_y,outputs)
        loss.backward()
        optimizer.step()
        train_epoch_loss.append(loss.item())
        train_loss.append(loss.item())
        if idx%(len(train_dataloader)//2)==0:
            print("epoch={}/{},{}/{}of train, loss={}".format(
                epoch, args.epochs, idx, len(train_dataloader),loss.item()))
    train_epochs_loss.append(np.average(train_epoch_loss))
    
    #=====================valid============================
    Your_model.eval()
    valid_epoch_loss = []
    for idx,(data_x,data_y) in enumerate(valid_dataloader,0):
        data_x = data_x.to(torch.float32).to(args.device)
        data_y = data_y.to(torch.float32).to(args.device)
        outputs = Your_model(data_x)
        loss = criterion(data_y,outputs)
        valid_epoch_loss.append(loss.item())
        valid_loss.append(loss.item())
    valid_epochs_loss.append(np.average(valid_epoch_loss))
    #==================early stopping======================
    early_stopping(valid_epochs_loss[-1],model=Your_model,path=r'c:\\your_model_to_save')
    if early_stopping.early_stop:
        print("Early stopping")
        break
    #====================adjust lr========================
    lr_adjust = {
            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,
            10: 5e-7, 15: 1e-7, 20: 5e-8
        }
    if epoch in lr_adjust.keys():
        lr = lr_adjust[epoch]
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
        print('Updating learning rate to {}'.format(lr))

### 八、绘图
plt.figure(figsize=(12,4))
plt.subplot(121)
plt.plot(train_loss[:])
plt.title("train_loss")
plt.subplot(122)
plt.plot(train_epochs_loss[1:],'-o',label="train_loss")
plt.plot(valid_epochs_loss[1:],'-o',label="valid_loss")
plt.title("epochs_loss")
plt.legend()
plt.show()

### 九、预测
# 此处可定义一个预测集的Dataloader。也可以直接将你的预测数据reshape,添加batch_size=1
Your_model.eval()
predict = Your_model(data)
```

下面是一个完整的例子，以18个数训练了一个分类网络，判断一个数字是否大于8（在`dataset`中设置），具有完整的训练和预测流程。网络是最简单的全连接，输入为1，输出为2（2分类）。

```python
import random

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

# 设置随机数种子保证论文可复现
seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)
torch.cuda.manual_seed_all(seed)

# 以类的方式定义参数，还有很多方法，config文件等等
class Args:
    def __init__(self) -> None:
        self.batch_size = 1
        self.lr = 0.001
        self.epochs = 10
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.data_train = np.array([-2, -1, 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 20])
        self.data_val = np.array([15, 16, 17, 0.1, -3, -4])


args = Args()

# 定义一个简单的全连接
class Net(nn.Module):
    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):
        super().__init__()
        self.layer1 = nn.Sequential(
            nn.Linear(in_dim, n_hidden_1), nn.ReLU(True))
        self.layer2 = nn.Sequential(
            nn.Linear(n_hidden_1, n_hidden_2), nn.ReLU(True))
        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        return x


# 定义数据集，判断一个数字是否大于8
class Dataset_num(Dataset):
    def __init__(self, flag='train') -> None:
        self.flag = flag
        assert self.flag in ['train', 'val'], 'not implement!'

        if self.flag == 'train':
            self.data = args.data_train
        else:
            self.data = args.data_val

    def __getitem__(self, index: int):
        val = self.data[index]

        if val > 8:
            label = 1
        else:
            label = 0

        return torch.tensor(label, dtype=torch.long), torch.tensor([val], dtype=torch.float32)

    def __len__(self) -> int:
        return len(self.data)


def train():
    train_dataset = Dataset_num(flag='train')
    train_dataloader = DataLoader(dataset=train_dataset, batch_size=args.batch_size, shuffle=True)
    val_dataset = Dataset_num(flag='val')
    val_dataloader = DataLoader(dataset=val_dataset, batch_size=args.batch_size, shuffle=True)

    model = Net(1, 32, 16, 2).to(args.device) # 网路参数设置，输入为1，输出为2，即判断一个数是否大于8
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)  # , eps=1e-8)

    train_epochs_loss = []
    valid_epochs_loss = []
    train_acc = []
    val_acc = []

    for epoch in range(args.epochs):
        model.train()
        train_epoch_loss = []
        acc, nums = 0, 0
        # =========================train=======================
        for idx, (label, inputs) in enumerate(tqdm(train_dataloader)):
            inputs = inputs.to(args.device)
            label = label.to(args.device)
            outputs = model(inputs)
            optimizer.zero_grad()
            loss = criterion(outputs, label)
            loss.backward()
            # torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0) #用来梯度裁剪
            optimizer.step()
            train_epoch_loss.append(loss.item())
            acc += sum(outputs.max(axis=1)[1] == label).cpu()
            nums += label.size()[0]
        train_epochs_loss.append(np.average(train_epoch_loss))
        train_acc.append(100 * acc / nums)
        print("train acc = {:.3f}%, loss = {}".format(100 * acc / nums, np.average(train_epoch_loss)))
        # =========================val=========================
        with torch.no_grad():
            model.eval()
            val_epoch_loss = []
            acc, nums = 0, 0

            for idx, (label, inputs) in enumerate(tqdm(val_dataloader)):
                inputs = inputs.to(args.device)  # .to(torch.float)
                label = label.to(args.device)
                outputs = model(inputs)
                loss = criterion(outputs, label)
                val_epoch_loss.append(loss.item())

                acc += sum(outputs.max(axis=1)[1] == label).cpu()
                nums += label.size()[0]

            valid_epochs_loss.append(np.average(val_epoch_loss))
            val_acc.append(100 * acc / nums)

            print("epoch = {}, valid acc = {:.2f}%, loss = {}".format(epoch, 100 * acc / nums, np.average(val_epoch_loss)))

    # =========================plot==========================
    plt.figure(figsize=(12, 4))
    plt.subplot(121)
    plt.plot(train_epochs_loss[:])
    plt.title("train_loss")
    plt.subplot(122)
    plt.plot(train_epochs_loss, '-o', label="train_loss")
    plt.plot(valid_epochs_loss, '-o', label="valid_loss")
    plt.title("epochs_loss")
    plt.legend()
    plt.show()
    # =========================save model=====================
    torch.save(model.state_dict(), 'model.pth')


def pred(val):
    model = Net(1, 32, 16, 2)
    model.load_state_dict(torch.load('model.pth'))
    model.eval()
    val = torch.tensor(val).reshape(1, -1).float()
    # 需要转换成相应的输入shape，而且得带上batch_size，因此转换成shape=(1,1)这样的形状
    res = model(val)
    # real: tensor([[-5.2095, -0.9326]], grad_fn=<AddmmBackward0>) 需要找到最大值所在的列数，就是标签
    res = res.max(axis=1)[1].item()
    print("predicted label is {}, {} {} 8".format(res, val.item(), ('>' if res == 1 else '<')))



if __name__ == '__main__':
    train()
    pred(24)
    pred(3.14)
    pred(7.8)  # 这个会预测错误，所以数据量对于深度学习很重要
```

### 2. 关于将值域为(0,1)的dtype=torch.float的图像Tensor转换为dtype=torch.unit8值域为(0,255)的图像Tensor的做法

位于[`torchvision.utils.save_image()`函数](https://github.com/pytorch/vision/blob/main/torchvision/utils.py)里

```python
# Add 0.5 after unnormalizing to [0, 255] to round to the nearest integer
ndarr = grid.mul(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to("cpu", torch.uint8).numpy()
im = Image.fromarray(ndarr)
im.save(fp, format=format)
```

其中`format`为存储格式，即`PILImage`的九种格式里的一种（比如`RGB`或者`RGBA`）。重点在于第一句，之所以再乘以$$255$$之后还加了$$0.5$$是因为，在`pytorch`里，将`dtype=torch.float`的`Tensor`转换为`dtype=torch.unit8`的`Tensor`时，值是向下取整的，比如说`torch.tensor(1.9, dtype=torch.float).to(torch.unit8)`的结果是$$1$$，所以加上$$0.5$$更加准确，也就是注释里说的，`round to the nearest integer`。


### 3. 使用`wandb`管理机器学习炼丹

`wandb`全称weights&bias，是一款类似`TensorBoard`的机器学习可视化以及分析工具。相比`TensorBoard`，`wandb`具有如下主要优势：

* 日志上传云端永久存储，便于分享不怕丢失。
* 可以存管代码,数据集和模型的版本，随时复现(`wandb.Artifact`)
* 可以使用交互式表格进行模型分析(`wandb.Table`)
* 可以自动化模型调参(`wandb.sweep`)

官方文档：https://docs.wandb.ai/

总体来说，wandb目前的核心功能有以下4个：
* 实验跟踪：experiment tracking (`wandb.log`)
* 版本管理：version management (`wandb.log_artifact`, `wandb.save`)
* case分析：case visualization (`wandb.Table`, `wandb.Image`)
* 超参调优：model optimization (`wandb.sweep`)

#### (1) 实验跟踪

`wandb`提供了类似`TensorBoard`的实验跟踪能力，主要包括：

* 模型配置超参数的记录
* 模型训练过程中`loss`，`metric`等各种指标的记录和可视化
* 图像的可视化(`wandb.Image`)
* 其他各种Media的可视化(`wandb.Vidio`, `wandb.Audio`, `wandb.Html`, 3D点云等)

如下例子介绍了一个使用`wandb`进行完整的实验跟踪的过程：

```python
import os
import PIL 
import numpy as np
from torch.utils.data import DataLoader, Dataset
import torch 
from torch import nn 
import torchvision 
from torchvision import transforms
import datetime
import wandb 
from argparse import Namespace

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
config = Namespace(
    project_name = 'wandb_demo',
    batch_size = 512,
    hidden_layer_width = 64,
    dropout_p = 0.1,
    lr = 1e-4,
    optim_type = 'Adam',
    epochs = 15,
    ckpt_path = 'checkpoint.pt'
)

def create_dataloaders(config):
    transform = transforms.Compose([transforms.ToTensor()])
    ds_train = torchvision.datasets.MNIST(root="./mnist/",train=True,download=True,transform=transform)
    ds_val = torchvision.datasets.MNIST(root="./mnist/",train=False,download=True,transform=transform)
    ds_train_sub = torch.utils.data.Subset(ds_train, indices=range(0, len(ds_train), 5))
    dl_train =  torch.utils.data.DataLoader(ds_train_sub, batch_size=config.batch_size, shuffle=True,num_workers=2,drop_last=True)
    dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=config.batch_size, shuffle=False, num_workers=2,drop_last=True)

    return dl_train,dl_val


def create_net(config):
    net = nn.Sequential()
    net.add_module("conv1",nn.Conv2d(in_channels=1,out_channels=config.hidden_layer_width,kernel_size = 3))
    net.add_module("pool1",nn.MaxPool2d(kernel_size = 2,stride = 2)) 
    net.add_module("conv2",nn.Conv2d(in_channels=config.hidden_layer_width,out_channels=config.hidden_layer_width,kernel_size = 5))
    net.add_module("pool2",nn.MaxPool2d(kernel_size = 2,stride = 2))
    net.add_module("dropout",nn.Dropout2d(p = config.dropout_p))
    net.add_module("adaptive_pool",nn.AdaptiveMaxPool2d((1,1)))
    net.add_module("flatten",nn.Flatten())
    net.add_module("linear1",nn.Linear(config.hidden_layer_width,config.hidden_layer_width))
    net.add_module("relu",nn.ReLU())
    net.add_module("linear2",nn.Linear(config.hidden_layer_width,10))
    net.to(device)

    return net

def train_epoch(model,dl_train,optimizer):
    model.train()
    for step, batch in enumerate(dl_train):
        features,labels = batch
        features,labels = features.to(device),labels.to(device)
        preds = model(features)
        loss = nn.CrossEntropyLoss()(preds,labels)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

    return model

def eval_epoch(model,dl_val):
    model.eval()
    accurate = 0
    num_elems = 0
    for batch in dl_val:
        features,labels = batch
        features,labels = features.to(device),labels.to(device)
        with torch.no_grad():
            preds = model(features)
        predictions = preds.argmax(dim=-1)
        accurate_preds =  (predictions==labels)
        num_elems += accurate_preds.shape[0]
        accurate += accurate_preds.long().sum()
    val_acc = accurate.item() / num_elems

    return val_acc


def train(config = config):
    dl_train, dl_val = create_dataloaders(config)
    model = create_net(config); 
    optimizer = torch.optim.__dict__[config.optim_type](params=model.parameters(), lr=config.lr)

    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    wandb.init(project=config.project_name, config = config.__dict__, name = nowtime, save_code=True)
    model.run_id = wandb.run.id

    model.best_metric = -1.0
    for epoch in range(1,config.epochs+1):
        model = train_epoch(model,dl_train,optimizer)
        val_acc = eval_epoch(model,dl_val)
        if val_acc>model.best_metric:
            model.best_metric = val_acc
            torch.save(model.state_dict(),config.ckpt_path)   
        nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"epoch{epoch}@{nowtime} --> val_acc= {100 * val_acc:.2f}%")

        wandb.log({'epoch':epoch, 'val_acc': val_acc, 'best_val_acc':model.best_metric})

    wandb.finish()

    return model

if __name__ == '__main__':
    model = train(config)
```

#### (2) 版本管理

除了可以记录实验日志传递到`wandb`网站的云端服务器并进行可视化分析，`wandb`还能够将实验关联的数据集，代码和模型保存到`wandb`服务器，便于我们或者其他人之后对实验结果进行复现。我们可以通过`wandb.log_artifact`的方法来保存任务的关联的重要成果，例如dataset, code，和 model，并进行版本管理。一般的流程是，先使用`run_id`恢复run任务，以便继续记录。

```python
# resume the run 
import wandb 
run = wandb.init(project='wandb_demo', id= model.run_id, resume='must')

# save dataset 
arti_dataset = wandb.Artifact('mnist', type='dataset')
arti_dataset.add_dir('mnist/')
wandb.log_artifact(arti_dataset)

# save code 
arti_code = wandb.Artifact('ipynb', type='code')
arti_code.add_file('./model_analysis.ipynb')
wandb.log_artifact(arti_code)

# save model
arti_model = wandb.Artifact('cnn', type='model')
arti_model.add_file(config.ckpt_path)
wandb.log_artifact(arti_model)
wandb.finish() # finish时会提交保存
```


#### (3) case分析

利用`wandb.Table`，我们可以在`wandb`的`dashboard`进行交互式可视化的case分析。

```python
# resume the run 
import wandb 
run = wandb.init(project=config.project_name, id= model.run_id, resume='must')
import matplotlib.pyplot as plt 

transform = transforms.Compose([transforms.ToTensor()])
ds_train = torchvision.datasets.MNIST(root="./mnist/",train=True,download=True,transform=transform)
ds_val = torchvision.datasets.MNIST(root="./mnist/",train=False,download=True,transform=transform)
    
# visual the  prediction

device = None
for p in model.parameters():
    device = p.device
    break

plt.figure(figsize=(8,8)) 
for i in range(9):
    img,label = ds_val[i]
    tensor = img.to(device)
    y_pred = torch.argmax(model(tensor[None,...])) 
    img = img.permute(1,2,0)
    ax=plt.subplot(3,3,i+1)
    ax.imshow(img.numpy())
    ax.set_title("y_pred = %d"%y_pred)
    ax.set_xticks([])
    ax.set_yticks([]) 
plt.show()    
def data2fig(data):
    import matplotlib.pyplot as plt 
    fig = plt.figure()
    ax = fig.add_subplot()
    ax.imshow(data)
    ax.set_xticks([])
    ax.set_yticks([]) 
    return fig

def fig2img(fig):
    import io,PIL
    buf = io.BytesIO()
    fig.savefig(buf)
    buf.seek(0)
    img = PIL.Image.open(buf)
    return img
from tqdm import tqdm 
good_cases = wandb.Table(columns = ['Image','GroundTruth','Prediction'])
bad_cases = wandb.Table(columns = ['Image','GroundTruth','Prediction'])
# 找到50个good cases 和 50 个bad cases

plt.close()

for i in tqdm(range(1000)):
    features,label = ds_val[i]
    tensor = features.to(device)
    y_pred = torch.argmax(model(tensor[None,...])) 
    
    # log badcase
    if y_pred!=label:
        if len(bad_cases.data)<50:
            data = features.permute(1,2,0).numpy()
            input_img = wandb.Image(fig2img(data2fig(data)))
            bad_cases.add_data(input_img,label,y_pred)
            
    # log goodcase
    else:
        if len(good_cases.data)<50:
            data = features.permute(1,2,0).numpy()
            input_img = wandb.Image(fig2img(data2fig(data)))
            good_cases.add_data(input_img,label,y_pred)
            
wandb.log({'good_cases':good_cases,'bad_cases':bad_cases})
wandb.finish()
```

在上述代码执行完毕后，相应的结果会存储在`DashBoard`里，然后我们就可以在`DashBoard`中对`Table`进行交互式的分析了，包括常用的`sort`, `filter`, `group`等操作（类似于excel）。

#### (4) `wandb.sweep`: 低代码、可视化、分布式自动调参工具。

使用`wandb`的`sweep`进行超参调优，具有以下优点：
* 低代码：只需配置一个`sweep.yaml`配置文件，或者定义一个配置`dict`，几乎不用编写调参相关代码。
* 可视化：在`wandb`网页中可以实时监控调参过程中的每次尝试，并可视化地分析调参任务的目标值分布，超参重要性等。
* 分布式：`sweep`采用类似`master-workers`的`controller-agents`架构，`controller`在`wandb`的服务器机器上运行，`agents`在用户机器上运行，`controller`和`agents`之间通过互联网进行通信。同时启动多个`agents`即可轻松实现分布式超参搜索。

> 但是使用`wandb`的`sweeps`调参的缺点是需要联网，由于`wandb`的`controller`位于`wandb`的服务器机器上，`wandb`日志也需要联网上传，在没有互联网的环境下无法正常使用`wandb`进行模型跟踪以及`wandb sweep`的可视化调参。

使用`wandb.sweep`的三个步骤如下：

* 配置`sweep_config`，配置调优算法，调优目标，需要优化的超参数列表等等。
* 初始化`sweep controller`：`sweep_id = wandb.sweep(sweep_config, project)`
* 启动`sweep agents`：`wandb.agent(sweep_id, function=train)`

```python
import os,PIL 
import numpy as np
from torch.utils.data import DataLoader, Dataset
import torch 
from torch import nn 
import torchvision 
from torchvision import transforms
import datetime
import wandb 

wandb.login()

from argparse import Namespace

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 初始化参数配置
config = Namespace(
    project_name = 'wandb_demo',
    batch_size = 512,
    hidden_layer_width = 64,
    dropout_p = 0.1,
    lr = 1e-4,
    optim_type = 'Adam',
    epochs = 15,
    ckpt_path = 'checkpoint.pt'
)
```

**1). 配置`sweep config`**

详细配置文档可以参考：https://docs.wandb.ai/guides/sweeps/define-sweep-configuration

首先，选择一个调优算法。`sweep`支持如下3种调优算法:
* 网格搜索`grid`：遍历所有可能得超参组合，只在超参空间不大的时候使用，否则会非常慢。
* 随机搜索`random`：每个超参数都选择一个随机值，非常有效，一般情况下建议使用。
* 贝叶斯搜索`bayes`：创建一个概率模型估计不同超参数组合的效果，采样有更高概率提升优化目标的超参数组合。对连续型的超参数特别有效，但扩展到非常高维度的超参数时效果不好。

```python
sweep_config = {'method': 'random'}
```

其次，定义调优目标。设置优化指标，以及优化方向。`sweep agents`通过`wandb.log`的形式向`sweep controller`传递优化目标的值。

```python
metric = {'name': 'val_acc', 'goal': 'maximize'}
sweep_config['metric'] = metric

## 'val_acc'是用户定义的，需要在`wandb.agent(sweep_id, function=train)`里的`train`函数利用`wandb.log()`进行记录。
```

最后，定义超参空间。超参空间可以分成，固定型、离散型和连续型：
* 固定型：指定value
* 离散型：指定 values，列出全部候选取值
* 连续性：需要指定分布类型（distribution），和范围（min, max），用于`random`或者`bayes`采样


```python
sweep_config['parameters'] = {}

# 固定不变的超参
sweep_config['parameters'].update({
    'project_name':{'value':'wandb_demo'},
    'epochs': {'value': 10},
    'ckpt_path': {'value':'checkpoint.pt'}})

# 离散型分布超参
sweep_config['parameters'].update({
    'optim_type': {
        'values': ['Adam', 'SGD','AdamW']
        },
    'hidden_layer_width': {
        'values': [16,32,48,64,80,96,112,128]
        }
    })

# 连续型分布超参
sweep_config['parameters'].update({
    'lr': {
        'distribution': 'log_uniform_values',
        'min': 1e-6,
        'max': 0.1
      },
    'batch_size': {
        'distribution': 'q_uniform',
        'q': 8,
        'min': 32,
        'max': 256,
      },
    'dropout_p': {
        'distribution': 'uniform',
        'min': 0,
        'max': 0.6,
      }
})
```

还有个可选项：定义剪枝策略。可以定义剪枝策略，提前终止那些没有希望的任务。

```python
sweep_config['early_terminate'] = {
    'type':'hyperband',
    'min_iter':3,
    'eta':2,
    's':3
}
# 在step=3, 6, 12时考虑是否剪枝
```

**2).初始化`sweep controller`**

```python
sweep_id = wandb.sweep(sweep_config, project=config.project_name)
```

**3).启动`sweep agent`**

我们需要把模型训练相关的全部代码整理成一个`train`函数，并且`train`函数里需要使用`wandb.log()`记录`sweep_config.metric.name`变量（即上述`val_loss`）

```python

def create_dataloaders(config):
    transform = transforms.Compose([transforms.ToTensor()])
    ds_train = torchvision.datasets.MNIST(root="./mnist/",train=True,download=True,transform=transform)
    ds_val = torchvision.datasets.MNIST(root="./mnist/",train=False,download=True,transform=transform)
    ds_train_sub = torch.utils.data.Subset(ds_train, indices=range(0, len(ds_train), 5))
    dl_train =  torch.utils.data.DataLoader(ds_train_sub, batch_size=config.batch_size, shuffle=True,num_workers=2,drop_last=True)
    dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=config.batch_size, shuffle=False, num_workers=2,drop_last=True)

    return dl_train,dl_val

def create_net(config):
    net = nn.Sequential()
    net.add_module("conv1",nn.Conv2d(in_channels=1,out_channels=config.hidden_layer_width,kernel_size = 3))
    net.add_module("pool1",nn.MaxPool2d(kernel_size = 2,stride = 2)) 
    net.add_module("conv2",nn.Conv2d(in_channels=config.hidden_layer_width,out_channels=config.hidden_layer_width,kernel_size = 5))
    net.add_module("pool2",nn.MaxPool2d(kernel_size = 2,stride = 2))
    net.add_module("dropout",nn.Dropout2d(p = config.dropout_p))
    net.add_module("adaptive_pool",nn.AdaptiveMaxPool2d((1,1)))
    net.add_module("flatten",nn.Flatten())
    net.add_module("linear1",nn.Linear(config.hidden_layer_width,config.hidden_layer_width))
    net.add_module("relu",nn.ReLU())
    net.add_module("linear2",nn.Linear(config.hidden_layer_width,10))

    return net 

def train_epoch(model,dl_train,optimizer):
    model.train()
    for step, batch in enumerate(dl_train):
        features,labels = batch
        features,labels = features.to(device),labels.to(device)
        preds = model(features)
        loss = nn.CrossEntropyLoss()(preds,labels)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

    return model

def eval_epoch(model, dl_val):
    model.eval()
    accurate = 0
    num_elems = 0
    for batch in dl_val:
        features,labels = batch
        features,labels = features.to(device),labels.to(device)
        with torch.no_grad():
            preds = model(features)
        predictions = preds.argmax(dim=-1)
        accurate_preds =  (predictions==labels)
        num_elems += accurate_preds.shape[0]
        accurate += accurate_preds.long().sum()

    val_acc = accurate.item() / num_elems

    return val_acc

def train(config = config):
    dl_train, dl_val = create_dataloaders(config)
    model = create_net(config); 
    optimizer = torch.optim.__dict__[config.optim_type](params=model.parameters(), lr=config.lr)
    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    wandb.init(project=config.project_name, config = config.__dict__, name = nowtime, save_code=True)
    model.run_id = wandb.run.id
    model.best_metric = -1.0
    for epoch in range(1,config.epochs+1):
        model = train_epoch(model,dl_train,optimizer)
        val_acc = eval_epoch(model,dl_val)
        if val_acc>model.best_metric:
            model.best_metric = val_acc
            torch.save(model.state_dict(),config.ckpt_path)   
        nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"epoch{epoch}@{nowtime} --> val_acc= {100 * val_acc:.2f}%")
        wandb.log({'epoch':epoch, 'val_acc': val_acc, 'best_val_acc':model.best_metric})

    wandb.finish()

    return model   

#model = train(config)
```

在`train`定义完毕之后，就可以启动搜索了：

```python
# 该`agent`随机搜索，尝试5次
wandb.agent(sweep_id, train, count=5)
```

**4). 调参可视化和跟踪**

* 平行坐标系图（Parallel Coordinates Plot）：将超参数值映射到模型度量，可以直观展示哪些超参数组合更加容易获取更好的结果。​
* 超参数重要性图（Hyperparameter Importance Plot）：超参数的重要性图展现了哪些超参数是指标的最佳预测因素。报告特征重要性（来自随机森林模型）和相关性（隐含线性模型），可以显示超参数和优化目标最终取值的重要性，和相关性方向。

 ![sweep0]({{ '/assets/images/sweep0.png' | relative_url }}){: style="width: 800px;" class="center"}
重要性显示了每个参数在预测所选度量方面有用的程度。相关性捕获单个超参数和度量值之间的线性关系。他们回答了使用该超参数和`sweep_config['metric']['name']`之间是否存在显着关系的这个问题。相关值范围为`-1`到`1`，其中正值代表正线性相关，负值代表负线性相关，值为`0`表示不相关。重要性与相关性之间的差异是重要性解释了超参数之间的相互作用，而相关性仅测量单个超参数对度量值的影响。其次，相关仅捕获线性关系，而重要性可以捕获更复杂的关系。

**参考链接**
* https://docs.wandb.ai/guides/sweeps/
* https://github.com/lyhue1991/eat_pytorch_in_20_days/blob/master/A-6%2C30%E5%88%86%E9%92%9F%E5%90%83%E6%8E%89wandb%E5%8F%AF%E8%A7%86%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90.ipynb
* https://github.com/lyhue1991/eat_pytorch_in_20_days/blob/master/A-7,30%E5%88%86%E9%92%9F%E5%90%83%E6%8E%89wandb%E5%8F%AF%E8%A7%86%E5%8C%96%E8%87%AA%E5%8A%A8%E8%B0%83%E5%8F%82.ipynb
* https://zhuanlan.zhihu.com/p/666696304


### 3. 另一个版本的`wandb.sweep`用法介绍

`wandb.sweep`使用流程如下：
* 定义`sweep_config`：包括定义搜索方式，超参范围空间
* 生成`sweep_id`：通过以下代码生成`sweep_id`：
```python
sweep_id = wandb.sweep(sweep_config, project='project_name')
```
* 定义`train`：定义train function，function实现同普通神经网络训练过程相同，不同的是相关超参数全部通过`wandb.config`赋值
* 运行：通过以下代码运行
```python
wandb.agent(sweep_id, train, count=10)
## count=10表明搜索10次
```

> `sweep_config`里的搜索方式有三种：`grid`：将各超参值进行全排列组合，然后迭代训练所有组合。`random`：在超参范围空间内随机选择一组超参，然后进行训练。`bayes`：选择模型的评价指标，建立各个超参对评价指标影响的概率预测模型，通过概率预测模型选择每次训练的超参数

> `sweep_config`里的`metric`定义通过哪个指标和哪个标准来进行选择超参数，`sweep_config['metric']`是一个`list`，包含`name`和`goal`两个`key`，分别表示使用哪个指标来计算，以及指定选择标准。`sweep_config['metric']['name']`是在`train`函数里使用`wandb.log()`记录的任意一个变量值，而`sweep_config['metric']['goal']`只能取两个值：`minimize`或者`maximize`，在`sweep_config['metric']`不包含`goal`变量时，默认使用`minimize`。

> `sweep_config`里的超参范围空间用来定义超参数以及给出相应的取值，具体格式如下所示，包括给出value、values以及按照某种分布取值三种方式：
```python
'learning_rate': {'value': 0.001}  ## 只给一个value就表明该参数值是固定的，只取这个值
'learning_rate': {'values': [0.001, 0.0001, 0.005]}  ## 给一个values列表表明该参数值从该列表里取
'learning_rate': {'distribution': 'uniform','min': 0,'max': 0.1}  ## 给一个distribution表明该参数值从该分布里取
```
> Sweep的目的是确定不同超参对模型性能的影响。因此使用`wandb.sweep`前，需要确定想要验证哪些超参，然后定义超参的范围空间。这里定义的超参将会在`train`中使用。

`wandb`的`sweep controller`会根据搜索方式和超参的范围空间生成一组超参。这组超参会在`train`中被使用。因此`train`的定义需要和超参范围空间中定义的超参一致。例如，希望验证不同`batch_size`和`learning_rate`在模型训练中的影响，在定义`train`时需要生成数据集，数据集的`batch_size`与`wandb.config['batch_size']`对应，同理`learning_rate`也需要与`wandb.config['learning_rate']`对应。具体如下所示：


> 注意，一般来说，需要被搜索的超参数都放在`sweep_config['parameters']`下，一般是一个字典

```python
def train(config=None):
    with wandb.init(config=config):
        config = wandb.config
        loader = data_load('amazon', config.batch_size)
        model= create_model(config.fc_size)
        optimizer = build_optimizer(model, config.optimizer, config.learning_rate)
        for epoch in range(config.epochs):
            avg_loss, accuracy = train_one_epoch(model, loader, optimizer)
            wandb.log({"loss": avg_loss, "accuracy": accuracy})

def data_load(sub_dir, batch_size, training=True):
    path = os.path.join('/home', sub_dir)
    transform = transforms.Compose(
            [transforms.RandomCrop(size=(224, 224)),
             transforms.RandomHorizontalFlip(),
             transforms.ToTensor(),
             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
             ])
    data = ImageFolder(path, transform)
    data = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)
 return data

def train_one_epoch(model, loader, optimizer):
    cumu_loss = 0
    correct = 0
    criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)
    for _, (data, target) in enumerate(loader):
        optimizer.zero_grad()
        outputs = model(data)
        loss = criterion(outputs, target)
        cumu_loss += loss.item()
        loss.backward()
        optimizer.step()
        predicted = torch.argmax(outputs, dim=1)
        correct += predicted.eq(target).sum().item()
        wandb.log({"batch_loss": loss.item()})
    return cumu_loss/len(loader), correct/len(loader.dataset)
```


如下是另外一个版本的`wandb.sweep`用法：

首先，`sweep_config`定义如下，是一个字典：
```python
{'method': 'random',
 'metric': {'goal': 'minimize', 'name': 'loss'},
 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values',
                               'max': 256,
                               'min': 32,
                               'q': 8},
                'dropout': {'values': [0.3, 0.4, 0.5]},
                'epochs': {'value': 1},
                'fc_layer_size': {'values': [128, 256, 512]},
                'learning_rate': {'distribution': 'uniform',
                                  'max': 0.1,
                                  'min': 0},
                'optimizer': {'values': ['adam', 'sgd']}}}
```

然后，定义`sweep_id`：

```python
sweep_id = wandb.sweep(sweep_config, project="pytorch-sweeps-demo")
```

最后，定义`train`函数：

```python
import torch
import torch.optim as optim
import torch.nn.functional as F
import torch.nn as nn
from torchvision import datasets, transforms

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def train(config=None):
    # Initialize a new wandb run
    with wandb.init(config=config):
        # If called by wandb.agent, as below,
        # this config will be set by Sweep Controller
        config = wandb.config

        loader = build_dataset(config.batch_size)
        network = build_network(config.fc_layer_size, config.dropout)
        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)

        for epoch in range(config.epochs):
            avg_loss = train_epoch(network, loader, optimizer)
            wandb.log({"loss": avg_loss, "epoch": epoch})           

def build_dataset(batch_size):
   
    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.1307,), (0.3081,))])
    # download MNIST training dataset
    dataset = datasets.MNIST(".", train=True, download=True,
                             transform=transform)
    sub_dataset = torch.utils.data.Subset(
        dataset, indices=range(0, len(dataset), 5))
    loader = torch.utils.data.DataLoader(sub_dataset, batch_size=batch_size)

    return loader


def build_network(fc_layer_size, dropout):
    network = nn.Sequential(  # fully-connected, single hidden layer
        nn.Flatten(),
        nn.Linear(784, fc_layer_size), nn.ReLU(),
        nn.Dropout(dropout),
        nn.Linear(fc_layer_size, 10),
        nn.LogSoftmax(dim=1))

    return network.to(device)
        

def build_optimizer(network, optimizer, learning_rate):
    if optimizer == "sgd":
        optimizer = optim.SGD(network.parameters(),
                              lr=learning_rate, momentum=0.9)
    elif optimizer == "adam":
        optimizer = optim.Adam(network.parameters(),
                               lr=learning_rate)
    return optimizer


def train_epoch(network, loader, optimizer):
    cumu_loss = 0
    for _, (data, target) in enumerate(loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()

        # ➡ Forward pass
        loss = F.nll_loss(network(data), target)
        cumu_loss += loss.item()

        # ⬅ Backward pass + weight update
        loss.backward()
        optimizer.step()

        wandb.log({"batch loss": loss.item()})

    return cumu_loss / len(loader)
```

运行`wandb.sweep`：

```python
wandb.agent(sweep_id, train, count=5)
```


**参考链接**
* https://docs.wandb.ai/guides/sweeps/
* https://zhuanlan.zhihu.com/p/666696304
* https://xandra298.github.io/posts/bad385cb/

## 1. PyTorch函数

### 1.1 scatter_ 和 scatter method

这个method是tensor所拥有的，而scartter和scatter_的用法是一样的，区别仅在于，scatter method会返回一个新的tensor，而scatter_仅改变原tensor，而不返回新的tensor。在PyTorch里，所有带一个下划线结束的tensor的method都是类似的效果。所以我们仅介绍scatter method的用法即可。

scatter method的用法为：

```python
target.scatter(dim, index, src)
```
> * target：即目标张量，将在该张量上进行映射
> * src：即源张量，将把该张量上的元素逐个映射到目标张量上
> * dim：指定轴方向，定义了填充方式。对于二维张量，dim=0表示逐列进行行填充，而dim=1表示逐列进行行填充
> * index: 按照轴方向，在target张量中需要填充的位置

为了保证scatter填充的有效性，需要注意：
* （1）target张量在dim方向上的长度不小于source张量，且在其它轴方向的长度与source张量一般相同。这里的一般是指：scatter操作本身有broadcast机制。
* （2）index张量的shape一般与source相同，从而定义了每个source元素的填充位置。这里的一般是指broadcast机制下的例外情况，也就是和第一点里的情况相同。

例子1：
```python
a = torch.arange(10).reshape((2, 5)).float()
b = torch.zeros(3, 5)
b_ = b.scatter(0, index=torch.tensor([[1,2,1,1,2], [2,0,2,1,0]], dtype=torch.int64), a)
print(b_)

# torch.tensor([[0., 6., 0., 0., 9.],
                [0., 0., 2., 8., 0.],
                [5., 1., 7., 0., 4.]])
```

例子2：
scatter函数的一个典型应用就是在分类问题中，将目标标签转换为one-hot编码形式，如：

```python
labels = torch.tensor([1, 3], dtype=torch.int64)
targets = torch.zeros(2, 5)
targets_ = targets.scatter(1, labels.unsqueeze(-1), 1.0)
print(targets_)

# torch.tensor([[0., 1., 0., 0., 0.],
                [0., 0., 0., 1., 0.]])
```

### 1.2 torch.mul()，torch.mm()以及torch.bmm

torch.mul(a,b)是矩阵$$a$$和$$b$$对应位置的元素相乘，需要$$a$$和$$b$$维度相同（或者满足broadcasting），得到的结果也和$$a$$以及$$b$$维度相同。

torch.mm(a,b)是矩阵$$a$$和$$b$$的矩阵相乘，注意$$a$$和$$b$$都必须是2维矩阵。

注意$$\ast$$和torch.mul()用法一样，$$@$$和torch.mm()用法一样。

torch.bmm(a,b)是专门用来进行batch的矩阵乘法的，也就是说$$a$$尺寸为$$b \times n \times m$$，$$b$$的尺寸为$$b \times m \times p$$，结果尺寸为$$b \times n \times p$$，具体计算为对第一个维度的每个2维矩阵，进行矩阵乘法。torch.bmm的作用就是为了第一个维度为batch来及逆行的矩阵乘法，因为torch.mm只能针对2维矩阵乘法，不方便。


## 2. PyTorch机制

### 2.1 model.eval()和torch.no_grad()的区别

在PyTorch代码里，这两个一般都用在推理阶段，但它们的作用是完全不同的，也没有重叠，可以一起使用。

对于model.eval()来说，经常在模型推理代码的前面，都会添加model.eval()，主要有3个作用：

* 不进行dropout
* 不更新batchnorm的mean和var参数
* 不进行梯度反向传播，**但梯度仍然会计算**

torch.no_grad的一般使用方法是，在代码块外面用with torch.no_grad()给包起来。如下面这样：

```python
with torch.no_grad():
    ## your code
```

它的主要作用有2个：

* 不进行梯度的计算(当然也就没办法反向传播了)，节约显存和算力
* dropout和batchnorm还是会正常更新


## 3. torchvision模块

### 3.1 torchvision.transforms模块

此模块的作用是对输入的图片进行某种preprocessing，比如resize，flip等。

#### 3.1.1 transforms.ToTensor()函数
`ToTensor()`将shape为$$(H, W, C)$$的`numpy.ndarray`或由`PIL.Image.open()`读入的`Image`类型的图片数据，转为shape为$$(C, H, W)$$的`Tensor`数据类型，并且还对输入的数据执行除以255的操作。

```python
import torchvision.transforms as transforms
import numpy as np
from PIL import Image
from __future__ import print_function

## 定义转换方式，transforms.Compose将多个转换函数组合起来使用
transform = transforms.Compose([transforms.ToTensor()])

## 定义一个numpy数组
np_array = np.random.rand(4,6,3)

## 直接使用函数归一化
np_tran = transform(np_array)

## 手动归一化
np_temp = torch.from_numpy(np_array.transpose((2,0,1)))
np_manu = np_temp.float().div(255)
print(np_tran.equal(np_manu))

## 输出为True

## 用Image读取一张图片
img = Image.open("xxx.png").convert("RGB")
img_tran = transform(img)
print(np.asarray(img).shape, img_tran.shape, img_tran.type)

## 输出分别为：Height x Width x 3，3 x Height x Width，Tensor
```

#### 3.1.2 transforms.Normalize()函数

在`transforms.Compose([transforms.ToTensor()])`中加入`transforms.Normalize()`，如下所示：`transforms.Compose([transforms.ToTensor(),transforms.Normalize(std=(0.5,0.5,0.5),mean=(0.5,0.5,0.5))])`，则其作用就是先将输入归一化到$$(0,1)$$，再使用公式$$(x-mean)/std$$，将每个元素分布到$$(-1,1)$$

```python
import torchvision.transforms as transforms

## 归一化到(0,1)之后，再执行(x-mean)/std，归一化到(-1,1)
transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(std=(0.5,0.5,0.5),mean=(0.5,0.5,0.5))]) 

np_array = np.random.rand(4,6,3)
np_tran = transform(np_array)

np_temp1 = torch.from_numpy(np_array.transpose((2,0,1)))
np_temp2 = np_temp1.float().div(255)
np.manu = np_temp2.sub_(0.5).div_(0.5)

print(np_tran.equal(manu))
## 输出为True
```

很多代码里面使用的`torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])`，这一组值`mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]`是从Imagenet训练集计算而来的，所以酌情使用该`mean`和`std`。

#### 3.1.3 transforms.Resize()函数

该函数用来调整由`PIL.Image`库读取的`PILImage`对象的尺寸，注意不能是用`scipy.io.imread`或者`cv2.imread`读取的图片，这两种方法得到的是`ndarray`，无法调整尺寸了。

具体用法是`torchvision.transforms.Resize(a)`或者`torchvision.transforms.Resize([h, w])`，其中前者表示将短边变成$$a$$，长宽比不变，后者指定变换后的长和宽（前者在输入图片长宽一样的情况就不能使用了）。

```python
from PIL import Image
from torchvision import transforms

img = Image.open('xxx.jpg')
w, h = img.size
resize = transforms.Resize([224,244])
img1 = resize(img)
img1.save('xxx1.jpg')
```

> 注意，`img1`是`img`在经过`transforms.Resize()`函数处理之后的对象，`img`是`PILImage`对象，可以看到`img1`仍然是`PILImage`对象，`transforms.Resize()`并没有将其变成`pytorch`的`Tensor`对象。

> 需要注意的一点是`PILImage`对象`size`属性返回的是`w, h`，而`transforms.Resize()`函数的的参数顺序是`h, w`。

---
